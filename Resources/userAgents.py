from bs4 import BeautifulSoup
import urllib2, json, io

URLS = ["http://www.useragentstring.com/pages/Chrome/",
		"http://www.useragentstring.com/_uas_Safari_version_.php"]

starter_word = "Mozilla"
main_list = []

def extract_urls():
	for url in URLS:
		response = urllib2.urlopen(url)
		html_txt = response.read()
		soup = BeautifulSoup(html_txt, 'html.parser')

		for link in soup.find_all('a'):
			if starter_word in link.string:
				main_list.append(link.string)

	with open('user_agents.json', 'w') as outfile:
	     json.dump(main_list, outfile, sort_keys = True, indent = 4,ensure_ascii=False)

def create_txt_file():
	with open('user_agents.json', 'r') as infile:
		list_agents = json.load(infile)
	for idx,agent in enumerate(list_agents):
		agent = agent.strip('"')
		list_agents[idx] = agent

	with open("./user_agent.txt", "w") as infile:
		for agent in list_agents:
			infile.write(agent + "\n")

create_txt_file()